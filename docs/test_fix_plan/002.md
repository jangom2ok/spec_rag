--- /home/runner/work/spec_rag/spec_rag/app/services/embedding_tasks.py 2025-07-25 03:10:16.407061+00:00
+++ /home/runner/work/spec_rag/spec_rag/app/services/embedding_tasks.py 2025-07-25 03:12:46.483120+00:00
@@ -115,10 +115,11 @@
     from celery.result import AsyncResult
 else:
     AsyncResult = MockAsyncResult

 logger = logging.getLogger(__name__)
+

# Celeryã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®š

def _create_celery_app():
     """Create Celery app with proper configuration"""
     # Force mock in test environment
@@ -128,11 +129,11 @@
         app = Celery(
             "embedding_tasks",
             broker="redis://localhost:6379/0",
             backend="redis://localhost:6379/0",
         )
-

+

  # Celeryè¨­å®š

     app.conf.update(
         task_serializer="json",
         accept_content=["json"],
         result_serializer="json",
@@ -143,10 +144,11 @@
         task_soft_time_limit=25 * 60,  # 25åˆ†ã§ã‚½ãƒ•ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
         worker_prefetch_multiplier=1,
         worker_max_tasks_per_child=1000,
     )
     return app
-

 celery_app =_create_celery_app()
would reformat /home/runner/work/spec_rag/spec_rag/app/services/embedding_tasks.py


         mock_metrics_service.query_metrics.side_effect = Exception("Metrics error")

-
+
         # ä¾å­˜æ€§ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
         async def failing_metrics_service():
             return mock_metrics_service
-

+
         app.dependency_overrides[get_metrics_service] = failing_metrics_service

-

+
         try:
             response = client.get(
                 "/v1/metrics", headers={"Authorization": "***"}
             )

@@ -287,11 +292,14 @@
             if "detail" in response_data:
                 assert "System metrics collection failed" in response_data["detail"]
             else:
                 # The error might be in a different format due to error handlers
                 assert "error" in response_data

-                assert "System metrics collection failed" in response_data["error"]["message"]

+                assert (
-                    "System metrics collection failed"
-                    in response_data["error"]["message"]
-                )
         finally:
             # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
             app.dependency_overrides.pop(get_metrics_service, None)


@@ -435,11 +443,14 @@
         if "detail" in response_data:
             assert "Task not found" in response_data["detail"]
         else:
             # The error might be in a different format due to error handlers
             assert "error" in response_data

-            assert "Task not found" in response_data["error"]["message"] or "not found" in response_data["error"]["message"].lower()

+            assert (
-                "Task not found" in response_data["error"]["message"]
-                or "not found" in response_data["error"]["message"].lower()
-            )

     @pytest.mark.asyncio
     async def test_get_reindex_status_error(self, override_admin_auth):
         """ãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""

would reformat /home/runner/work/spec_rag/spec_rag/tests/test_system_api.py

Oh no! ğŸ’¥ ğŸ’” ğŸ’¥
9 files would be reformatted, 82 files would be left unchanged.
Error: Process completed with exit code 1.
