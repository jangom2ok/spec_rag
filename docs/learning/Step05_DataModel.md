# Step05: „Éá„Éº„Çø„É¢„Éá„É´Ë®≠Ë®à„Å®„Çπ„Ç≠„Éº„ÉûË©≥Á¥∞

## üéØ „Åì„ÅÆÁ´†„ÅÆÁõÆÊ®ô
PostgreSQL„ÉªMilvus„Åß„ÅÆ„Éá„Éº„Çø„É¢„Éá„É´Ë®≠Ë®à„ÄÅ„Çπ„Ç≠„Éº„ÉûË©≥Á¥∞„ÄÅ„Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÊà¶Áï•„ÄÅ„Éá„Éº„ÇøÊï¥ÂêàÊÄß„ÅÆ‰ªïÁµÑ„Åø„ÇíÁêÜËß£„Åô„Çã

---

## üìã Ê¶ÇË¶Å

RAG„Ç∑„Çπ„ÉÜ„É†„Åß„ÅØ„ÄÅÊßãÈÄ†Âåñ„Éá„Éº„ÇøÔºà„É°„Çø„Éá„Éº„ÇøÔºâ„Å®ÈùûÊßãÈÄ†Âåñ„Éá„Éº„ÇøÔºà„Éô„ÇØ„Çø„ÉºÔºâ„ÇíÂäπÁéáÁöÑ„Å´ÁÆ°ÁêÜ„Åô„Çã„Åü„ÇÅ„ÄÅPostgreSQL„Å®Milvus„Çí‰Ωø„ÅÑÂàÜ„Åë„Å¶„ÅÑ„Åæ„Åô„ÄÇÈÅ©Âàá„Å™„Çπ„Ç≠„Éº„ÉûË®≠Ë®à„Å´„Çà„Çä„ÄÅÈ´òÈÄüÊ§úÁ¥¢„Å®Êã°ÂºµÊÄß„Çí‰∏°Á´ã„Åó„Åæ„Åô„ÄÇ

### üèóÔ∏è „Éá„Éº„Çø„Éô„Éº„ÇπÊßãÊàê

```
„Éá„Éº„Çø‰øùÂ≠òÊà¶Áï•
‚îú‚îÄ‚îÄ PostgreSQL        # ÊßãÈÄ†Âåñ„Éá„Éº„Çø„Éª„É°„Çø„Éá„Éº„Çø
‚îÇ   ‚îú‚îÄ‚îÄ documents     # „Éâ„Ç≠„É•„É°„É≥„ÉàÂü∫Êú¨ÊÉÖÂ†±
‚îÇ   ‚îú‚îÄ‚îÄ chunks        # „ÉÅ„É£„É≥„ÇØË©≥Á¥∞
‚îÇ   ‚îú‚îÄ‚îÄ sources       # „ÇΩ„Éº„ÇπÁÆ°ÁêÜ
‚îÇ   ‚îî‚îÄ‚îÄ users         # „É¶„Éº„Ç∂„Éº„ÉªË™çË®º
‚îú‚îÄ‚îÄ Milvus            # „Éô„ÇØ„Çø„Éº„Éá„Éº„Çø
‚îÇ   ‚îú‚îÄ‚îÄ dense_collection    # Dense vectors
‚îÇ   ‚îú‚îÄ‚îÄ sparse_collection   # Sparse vectors
‚îÇ   ‚îî‚îÄ‚îÄ multi_collection    # Multi-vectors
‚îî‚îÄ‚îÄ Redis             # „Ç≠„É£„ÉÉ„Ç∑„É•„Éª„Çª„ÉÉ„Ç∑„Éß„É≥
    ‚îú‚îÄ‚îÄ search_cache  # Ê§úÁ¥¢ÁµêÊûú„Ç≠„É£„ÉÉ„Ç∑„É•
    ‚îú‚îÄ‚îÄ embedding_cache # Âüã„ÇÅËæº„Åø„Ç≠„É£„ÉÉ„Ç∑„É•
    ‚îî‚îÄ‚îÄ session_store # „É¶„Éº„Ç∂„Éº„Çª„ÉÉ„Ç∑„Éß„É≥
```

---

## üóÉÔ∏è PostgreSQL „Çπ„Ç≠„Éº„ÉûË®≠Ë®à

### 1. „Éâ„Ç≠„É•„É°„É≥„ÉàÁÆ°ÁêÜ„ÉÜ„Éº„Éñ„É´

#### `documents` „ÉÜ„Éº„Éñ„É´
```sql
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    title VARCHAR(1000) NOT NULL,
    content TEXT NOT NULL,
    source_type VARCHAR(50) NOT NULL,
    source_id VARCHAR(255) NOT NULL,
    source_url TEXT,
    
    -- „É°„Çø„Éá„Éº„Çø
    author VARCHAR(255),
    language CHAR(2) DEFAULT 'ja',
    category VARCHAR(100),
    tags TEXT[], -- PostgreSQLÈÖçÂàó
    
    -- Áµ±Ë®àÊÉÖÂ†±
    word_count INTEGER DEFAULT 0,
    char_count INTEGER DEFAULT 0,
    chunk_count INTEGER DEFAULT 0,
    
    -- Âá¶ÁêÜÁä∂Ê≥Å
    processing_status VARCHAR(20) DEFAULT 'pending',
    indexing_status VARCHAR(20) DEFAULT 'pending',
    error_message TEXT,
    
    -- „Çø„Ç§„É†„Çπ„Çø„É≥„Éó
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    indexed_at TIMESTAMP WITH TIME ZONE,
    
    -- Âà∂Á¥Ñ
    CONSTRAINT valid_processing_status 
        CHECK (processing_status IN ('pending', 'processing', 'completed', 'failed')),
    CONSTRAINT valid_indexing_status 
        CHECK (indexing_status IN ('pending', 'indexing', 'completed', 'failed')),
    CONSTRAINT valid_language 
        CHECK (language ~ '^[a-z]{2}$'),
    CONSTRAINT positive_counts 
        CHECK (word_count >= 0 AND char_count >= 0 AND chunk_count >= 0)
);

-- „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
CREATE INDEX idx_documents_source ON documents (source_type, source_id);
CREATE INDEX idx_documents_status ON documents (processing_status, indexing_status);
CREATE INDEX idx_documents_created ON documents (created_at DESC);
CREATE INDEX idx_documents_language ON documents (language);
CREATE INDEX idx_documents_category ON documents (category);
CREATE INDEX idx_documents_tags ON documents USING GIN (tags);
CREATE UNIQUE INDEX idx_documents_source_unique ON documents (source_type, source_id);

-- ÂÖ®ÊñáÊ§úÁ¥¢„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
CREATE INDEX idx_documents_fulltext ON documents 
    USING GIN (to_tsvector('japanese', title || ' ' || content));
```

#### `document_chunks` „ÉÜ„Éº„Éñ„É´
```sql
CREATE TABLE document_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    
    -- „ÉÅ„É£„É≥„ÇØÂÜÖÂÆπ
    content TEXT NOT NULL,
    chunk_type VARCHAR(50) DEFAULT 'text',
    position INTEGER NOT NULL,
    
    -- ÊßãÈÄ†ÊÉÖÂ†±
    section_title VARCHAR(500),
    hierarchy_level INTEGER DEFAULT 1,
    parent_chunk_id UUID REFERENCES document_chunks(id),
    
    -- „Çµ„Ç§„Ç∫ÊÉÖÂ†±
    token_count INTEGER DEFAULT 0,
    char_count INTEGER DEFAULT 0,
    
    -- „Éô„ÇØ„Çø„ÉºÈñ¢ÈÄ£
    dense_vector_id VARCHAR(255), -- MilvusÂÜÖ„ÅÆID
    sparse_vector_id VARCHAR(255),
    multi_vector_id VARCHAR(255),
    
    -- Âá¶ÁêÜÁä∂Ê≥Å
    embedding_status VARCHAR(20) DEFAULT 'pending',
    embedding_error TEXT,
    
    -- „Çπ„Ç≥„Ç¢ÊÉÖÂ†±ÔºàÊ§úÁ¥¢ÊôÇ„Å´Êõ¥Êñ∞Ôºâ
    last_search_score FLOAT,
    search_count INTEGER DEFAULT 0,
    
    -- „Çø„Ç§„É†„Çπ„Çø„É≥„Éó
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    embedded_at TIMESTAMP WITH TIME ZONE,
    
    -- Âà∂Á¥Ñ
    CONSTRAINT valid_embedding_status 
        CHECK (embedding_status IN ('pending', 'processing', 'completed', 'failed')),
    CONSTRAINT positive_position CHECK (position >= 0),
    CONSTRAINT positive_counts 
        CHECK (token_count >= 0 AND char_count >= 0 AND hierarchy_level >= 1)
);

-- „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
CREATE INDEX idx_chunks_document ON document_chunks (document_id, position);
CREATE INDEX idx_chunks_embedding_status ON document_chunks (embedding_status);
CREATE INDEX idx_chunks_vector_ids ON document_chunks (dense_vector_id, sparse_vector_id);
CREATE INDEX idx_chunks_hierarchy ON document_chunks (hierarchy_level, section_title);
CREATE INDEX idx_chunks_parent ON document_chunks (parent_chunk_id);

-- ÂÖ®ÊñáÊ§úÁ¥¢
CREATE INDEX idx_chunks_fulltext ON document_chunks 
    USING GIN (to_tsvector('japanese', content));
```

### 2. „ÇΩ„Éº„ÇπÁÆ°ÁêÜ„ÉÜ„Éº„Éñ„É´

#### `sources` „ÉÜ„Éº„Éñ„É´
```sql
CREATE TABLE sources (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    source_type VARCHAR(50) NOT NULL,
    name VARCHAR(255) NOT NULL,
    
    -- Êé•Á∂öÊÉÖÂ†±
    connection_config JSONB NOT NULL,
    credentials_encrypted TEXT,
    
    -- ÂêåÊúüË®≠ÂÆö
    sync_schedule VARCHAR(100), -- CronÂºè
    last_sync_at TIMESTAMP WITH TIME ZONE,
    next_sync_at TIMESTAMP WITH TIME ZONE,
    sync_status VARCHAR(20) DEFAULT 'pending',
    
    -- Áµ±Ë®àÊÉÖÂ†±
    total_documents INTEGER DEFAULT 0,
    successful_documents INTEGER DEFAULT 0,
    failed_documents INTEGER DEFAULT 0,
    
    -- Áä∂ÊÖãÁÆ°ÁêÜ
    is_active BOOLEAN DEFAULT true,
    error_count INTEGER DEFAULT 0,
    last_error TEXT,
    
    -- „Çø„Ç§„É†„Çπ„Çø„É≥„Éó
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    CONSTRAINT valid_sync_status 
        CHECK (sync_status IN ('pending', 'running', 'completed', 'failed'))
);

-- „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
CREATE INDEX idx_sources_type ON sources (source_type);
CREATE INDEX idx_sources_active ON sources (is_active);
CREATE INDEX idx_sources_sync_schedule ON sources (next_sync_at) WHERE is_active = true;
CREATE UNIQUE INDEX idx_sources_name_type ON sources (source_type, name);
```

### 3. Ë™çË®º„Éª„É¶„Éº„Ç∂„ÉºÁÆ°ÁêÜ

#### `users` „ÉÜ„Éº„Éñ„É´
```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) NOT NULL UNIQUE,
    username VARCHAR(100) NOT NULL UNIQUE,
    password_hash VARCHAR(255) NOT NULL,
    
    -- „Éó„É≠„Éï„Ç£„Éº„É´
    full_name VARCHAR(255),
    avatar_url TEXT,
    timezone VARCHAR(50) DEFAULT 'Asia/Tokyo',
    
    -- Ê®©Èôê„Éª„É≠„Éº„É´
    role VARCHAR(50) DEFAULT 'viewer',
    permissions TEXT[], -- PostgreSQLÈÖçÂàó
    is_active BOOLEAN DEFAULT true,
    is_verified BOOLEAN DEFAULT false,
    
    -- „Çª„Ç≠„É•„É™„ÉÜ„Ç£
    failed_login_attempts INTEGER DEFAULT 0,
    locked_until TIMESTAMP WITH TIME ZONE,
    last_login_at TIMESTAMP WITH TIME ZONE,
    password_changed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- „Çø„Ç§„É†„Çπ„Çø„É≥„Éó
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    CONSTRAINT valid_role 
        CHECK (role IN ('viewer', 'editor', 'admin', 'super_admin')),
    CONSTRAINT valid_email 
        CHECK (email ~ '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$')
);

-- „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
CREATE INDEX idx_users_email ON users (email);
CREATE INDEX idx_users_role ON users (role);
CREATE INDEX idx_users_active ON users (is_active);
CREATE INDEX idx_users_permissions ON users USING GIN (permissions);
```

#### `api_keys` „ÉÜ„Éº„Éñ„É´
```sql
CREATE TABLE api_keys (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    
    -- API KeyÊÉÖÂ†±
    key_hash VARCHAR(255) NOT NULL UNIQUE,
    key_prefix VARCHAR(20) NOT NULL, -- Ë°®Á§∫Áî®„Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„Çπ
    name VARCHAR(255) NOT NULL,
    description TEXT,
    
    -- Ê®©Èôê
    permissions TEXT[] NOT NULL,
    rate_limit_per_minute INTEGER DEFAULT 100,
    
    -- ‰ΩøÁî®Áä∂Ê≥Å
    usage_count INTEGER DEFAULT 0,
    last_used_at TIMESTAMP WITH TIME ZONE,
    
    -- Áä∂ÊÖã
    is_active BOOLEAN DEFAULT true,
    expires_at TIMESTAMP WITH TIME ZONE,
    
    -- „Çø„Ç§„É†„Çπ„Çø„É≥„Éó
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    CONSTRAINT positive_rate_limit CHECK (rate_limit_per_minute > 0)
);

-- „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
CREATE INDEX idx_api_keys_user ON api_keys (user_id);
CREATE INDEX idx_api_keys_active ON api_keys (is_active);
CREATE INDEX idx_api_keys_expires ON api_keys (expires_at) WHERE expires_at IS NOT NULL;
```

---

## üîç Milvus „Éô„ÇØ„Çø„Éº„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥Ë®≠Ë®à

### 1. Dense Vector Collection

```python
from pymilvus import CollectionSchema, FieldSchema, DataType

# „Çπ„Ç≠„Éº„ÉûÂÆöÁæ©
dense_collection_schema = CollectionSchema(
    fields=[
        FieldSchema(
            name="id",
            dtype=DataType.VARCHAR,
            max_length=255,
            is_primary=True,
            description="„ÉÅ„É£„É≥„ÇØIDÔºàPostgreSQL„Å®ÈÄ£Êê∫Ôºâ"
        ),
        FieldSchema(
            name="vector",
            dtype=DataType.FLOAT_VECTOR,
            dim=1024,  # BGE-M3„ÅÆDense VectorÊ¨°ÂÖÉ
            description="1024Ê¨°ÂÖÉDense Vector"
        ),
        FieldSchema(
            name="document_id",
            dtype=DataType.VARCHAR,
            max_length=255,
            description="Ë¶™„Éâ„Ç≠„É•„É°„É≥„ÉàID"
        ),
        FieldSchema(
            name="source_type",
            dtype=DataType.VARCHAR,
            max_length=50,
            description="„ÇΩ„Éº„Çπ„Çø„Ç§„Éó"
        ),
        FieldSchema(
            name="language",
            dtype=DataType.VARCHAR,
            max_length=2,
            description="Ë®ÄË™û„Ç≥„Éº„Éâ"
        ),
        FieldSchema(
            name="chunk_position",
            dtype=DataType.INT32,
            description="„Éâ„Ç≠„É•„É°„É≥„ÉàÂÜÖ„ÅÆ‰ΩçÁΩÆ"
        ),
        FieldSchema(
            name="created_timestamp",
            dtype=DataType.INT64,
            description="‰ΩúÊàê„Çø„Ç§„É†„Çπ„Çø„É≥„ÉóÔºàUnixÊôÇÈñìÔºâ"
        )
    ],
    description="Dense vectors for semantic search",
    enable_dynamic_field=True  # Â∞ÜÊù•„ÅÆÊã°Âºµ„Å´ÂØæÂøú
)

# „Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπË®≠ÂÆö
dense_index_params = {
    "metric_type": "IP",  # Inner Product
    "index_type": "HNSW",
    "params": {
        "M": 16,              # „Ç∞„É©„Éï„ÅÆÊúÄÂ§ßÊé•Á∂öÊï∞
        "efConstruction": 256  # „Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÊßãÁØâÊôÇ„ÅÆÊé¢Á¥¢ÂπÖ
    }
}
```

### 2. Sparse Vector Collection

```python
# Sparse VectorÁî®„Çπ„Ç≠„Éº„Éû
sparse_collection_schema = CollectionSchema(
    fields=[
        FieldSchema(
            name="id",
            dtype=DataType.VARCHAR,
            max_length=255,
            is_primary=True
        ),
        FieldSchema(
            name="vector",
            dtype=DataType.SPARSE_FLOAT_VECTOR,
            description="Sparse VectorÔºàË™ûÂΩôÈáç„Åø„Éû„ÉÉ„ÉóÔºâ"
        ),
        FieldSchema(
            name="document_id",
            dtype=DataType.VARCHAR,
            max_length=255
        ),
        FieldSchema(
            name="source_type",
            dtype=DataType.VARCHAR,
            max_length=50
        ),
        FieldSchema(
            name="language",
            dtype=DataType.VARCHAR,
            max_length=2
        ),
        FieldSchema(
            name="chunk_position",
            dtype=DataType.INT32
        ),
        FieldSchema(
            name="vocabulary_size",
            dtype=DataType.INT32,
            description="ÊúâÂäπË™ûÂΩôÊï∞"
        ),
        FieldSchema(
            name="created_timestamp",
            dtype=DataType.INT64
        )
    ],
    description="Sparse vectors for keyword search"
)

# Sparse VectorÁî®„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
sparse_index_params = {
    "index_type": "SPARSE_INVERTED_INDEX",
    "metric_type": "IP",
    "params": {
        "drop_ratio_build": 0.2  # ‰ΩéÈ†ªÂ∫¶Ë™û„ÅÆÈô§Â§ñÁéá
    }
}
```

### 3. Multi-Vector Collection

```python
# Multi-VectorÔºàColBERTÔºâÁî®„Çπ„Ç≠„Éº„Éû
multi_collection_schema = CollectionSchema(
    fields=[
        FieldSchema(
            name="id",
            dtype=DataType.VARCHAR,
            max_length=255,
            is_primary=True
        ),
        FieldSchema(
            name="vectors",
            dtype=DataType.FLOAT_VECTOR,
            dim=1024,  # ÂêÑ„Éà„Éº„ÇØ„É≥„Éô„ÇØ„Çø„Éº„ÅÆÊ¨°ÂÖÉ
            description="„Éà„Éº„ÇØ„É≥„É¨„Éô„É´„Éô„ÇØ„Çø„Éº„ÅÆÈÖçÂàó"
        ),
        FieldSchema(
            name="token_count",
            dtype=DataType.INT32,
            description="„Éà„Éº„ÇØ„É≥Êï∞"
        ),
        FieldSchema(
            name="token_positions",
            dtype=DataType.JSON,  # „Éà„Éº„ÇØ„É≥‰ΩçÁΩÆÊÉÖÂ†±
            description="ÂêÑ„Éà„Éº„ÇØ„É≥„ÅÆ‰ΩçÁΩÆÊÉÖÂ†±"
        ),
        FieldSchema(
            name="document_id",
            dtype=DataType.VARCHAR,
            max_length=255
        ),
        FieldSchema(
            name="source_type",
            dtype=DataType.VARCHAR,
            max_length=50
        ),
        FieldSchema(
            name="chunk_position",
            dtype=DataType.INT32
        ),
        FieldSchema(
            name="created_timestamp",
            dtype=DataType.INT64
        )
    ],
    description="Multi-vectors for fine-grained search"
)
```

---

## üîó „Éá„Éº„ÇøÈñ¢ÈÄ£‰ªò„Åë„Å®„Éû„ÉÉ„Éî„É≥„Ç∞

### PostgreSQL ‚Üî Milvus ÈÄ£Êê∫

```python
@dataclass
class VectorMappingService:
    """PostgreSQL„Å®Milvus„ÅÆ„Éá„Éº„ÇøÈÄ£Êê∫ÁÆ°ÁêÜ"""
    
    async def save_chunk_with_vectors(
        self,
        chunk_data: dict,
        dense_vector: list[float],
        sparse_vector: dict,
        multi_vectors: list[list[float]]
    ) -> str:
        """„ÉÅ„É£„É≥„ÇØ„Éá„Éº„Çø„Å®„Éô„ÇØ„Çø„Éº„ÇíÈÄ£Êê∫‰øùÂ≠ò"""
        
        chunk_id = str(uuid.uuid4())
        
        try:
            # 1. PostgreSQL„Å´„ÉÅ„É£„É≥„ÇØ„É°„Çø„Éá„Éº„Çø„Çí‰øùÂ≠ò
            async with self.postgres_pool.acquire() as conn:
                await conn.execute("""
                    INSERT INTO document_chunks 
                    (id, document_id, content, position, token_count, embedding_status)
                    VALUES ($1, $2, $3, $4, $5, 'processing')
                """, chunk_id, chunk_data["document_id"], 
                    chunk_data["content"], chunk_data["position"], 
                    chunk_data["token_count"])
            
            # 2. Milvus„Å´„Éô„ÇØ„Çø„Éº„Çí‰øùÂ≠ò
            vector_ids = await self._save_vectors_to_milvus(
                chunk_id, dense_vector, sparse_vector, multi_vectors
            )
            
            # 3. PostgreSQL„Å´„Éô„ÇØ„Çø„ÉºID„ÇíÊõ¥Êñ∞
            async with self.postgres_pool.acquire() as conn:
                await conn.execute("""
                    UPDATE document_chunks 
                    SET dense_vector_id = $1, sparse_vector_id = $2, 
                        multi_vector_id = $3, embedding_status = 'completed',
                        embedded_at = NOW()
                    WHERE id = $4
                """, vector_ids["dense"], vector_ids["sparse"], 
                    vector_ids["multi"], chunk_id)
            
            return chunk_id
            
        except Exception as e:
            # „É≠„Éº„É´„Éê„ÉÉ„ÇØÂá¶ÁêÜ
            await self._cleanup_failed_chunk(chunk_id)
            raise RuntimeError(f"Chunk saving failed: {e}")
    
    async def _save_vectors_to_milvus(
        self,
        chunk_id: str,
        dense_vector: list[float],
        sparse_vector: dict,
        multi_vectors: list[list[float]]
    ) -> dict[str, str]:
        """Milvus„Å´„Éô„ÇØ„Çø„Éº„Çí‰øùÂ≠ò„Åó„ÄÅID„ÇíËøîÂç¥"""
        
        vector_ids = {}
        
        # Dense Vector‰øùÂ≠ò
        dense_data = {
            "id": f"{chunk_id}_dense",
            "vector": dense_vector,
            "document_id": chunk_id.split("_")[0],
            "created_timestamp": int(time.time())
        }
        await self.milvus_client.insert("dense_collection", [dense_data])
        vector_ids["dense"] = dense_data["id"]
        
        # Sparse Vector‰øùÂ≠ò
        sparse_data = {
            "id": f"{chunk_id}_sparse",
            "vector": sparse_vector,
            "document_id": chunk_id.split("_")[0],
            "vocabulary_size": len(sparse_vector),
            "created_timestamp": int(time.time())
        }
        await self.milvus_client.insert("sparse_collection", [sparse_data])
        vector_ids["sparse"] = sparse_data["id"]
        
        # Multi-Vector‰øùÂ≠ò
        multi_data = {
            "id": f"{chunk_id}_multi",
            "vectors": multi_vectors,
            "token_count": len(multi_vectors),
            "document_id": chunk_id.split("_")[0],
            "created_timestamp": int(time.time())
        }
        await self.milvus_client.insert("multi_collection", [multi_data])
        vector_ids["multi"] = multi_data["id"]
        
        return vector_ids
```

---

## üìä „Éá„Éº„ÇøÊï¥ÂêàÊÄß„Å®Âà∂Á¥Ñ

### 1. Â§ñÈÉ®„Ç≠„ÉºÂà∂Á¥Ñ„Å®ÂâäÈô§„Ç´„Çπ„Ç±„Éº„Éâ

```sql
-- „Éâ„Ç≠„É•„É°„É≥„ÉàÂâäÈô§ÊôÇ„ÅÆ„Ç´„Çπ„Ç±„Éº„ÉâÂá¶ÁêÜ
CREATE OR REPLACE FUNCTION cleanup_document_vectors()
RETURNS TRIGGER AS $$
DECLARE
    chunk_record RECORD;
BEGIN
    -- ÂâäÈô§„Åï„Çå„Çã„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆ„ÉÅ„É£„É≥„ÇØID„ÇíÂèñÂæó
    FOR chunk_record IN 
        SELECT dense_vector_id, sparse_vector_id, multi_vector_id 
        FROM document_chunks 
        WHERE document_id = OLD.id
    LOOP
        -- Milvus„ÅÆ„Éô„ÇØ„Çø„Éº„ÇíÈùûÂêåÊúü„ÅßÂâäÈô§ÔºàÂ§ñÈÉ®Èñ¢Êï∞ÁµåÁî±Ôºâ
        PERFORM delete_milvus_vectors(
            chunk_record.dense_vector_id,
            chunk_record.sparse_vector_id, 
            chunk_record.multi_vector_id
        );
    END LOOP;
    
    RETURN OLD;
END;
$$ LANGUAGE plpgsql;

-- „Éà„É™„Ç¨„ÉºË®≠ÂÆö
CREATE TRIGGER trigger_cleanup_document_vectors
    AFTER DELETE ON documents
    FOR EACH ROW
    EXECUTE FUNCTION cleanup_document_vectors();
```

### 2. „Éá„Éº„ÇøÁä∂ÊÖã‰∏ÄË≤´ÊÄß„ÉÅ„Çß„ÉÉ„ÇØ

```python
class DataConsistencyChecker:
    """„Éá„Éº„ÇøÊï¥ÂêàÊÄß„ÉÅ„Çß„ÉÉ„Ç´„Éº"""
    
    async def check_consistency(self) -> dict[str, Any]:
        """„Ç∑„Çπ„ÉÜ„É†ÂÖ®‰Ωì„ÅÆÊï¥ÂêàÊÄß„ÉÅ„Çß„ÉÉ„ÇØ"""
        
        inconsistencies = {
            "orphaned_chunks": [],
            "missing_vectors": [],
            "status_mismatches": [],
            "index_issues": []
        }
        
        # 1. Â≠§Á´ã„ÉÅ„É£„É≥„ÇØ„ÉÅ„Çß„ÉÉ„ÇØ
        orphaned = await self._check_orphaned_chunks()
        inconsistencies["orphaned_chunks"] = orphaned
        
        # 2. Ê¨†Êêç„Éô„ÇØ„Çø„Éº„ÉÅ„Çß„ÉÉ„ÇØ  
        missing_vectors = await self._check_missing_vectors()
        inconsistencies["missing_vectors"] = missing_vectors
        
        # 3. „Çπ„ÉÜ„Éº„Çø„Çπ‰∏çÊï¥Âêà„ÉÅ„Çß„ÉÉ„ÇØ
        status_issues = await self._check_status_consistency()
        inconsistencies["status_mismatches"] = status_issues
        
        # 4. „Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÊï¥ÂêàÊÄß„ÉÅ„Çß„ÉÉ„ÇØ
        index_issues = await self._check_index_consistency()
        inconsistencies["index_issues"] = index_issues
        
        return inconsistencies
    
    async def _check_orphaned_chunks(self) -> list[dict]:
        """Ë¶™„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆ„Å™„ÅÑ„ÉÅ„É£„É≥„ÇØ„ÇíÊ§úÂá∫"""
        async with self.postgres_pool.acquire() as conn:
            results = await conn.fetch("""
                SELECT c.id, c.document_id, c.content
                FROM document_chunks c
                LEFT JOIN documents d ON c.document_id = d.id
                WHERE d.id IS NULL
            """)
            return [dict(r) for r in results]
    
    async def _check_missing_vectors(self) -> list[dict]:
        """„Éô„ÇØ„Çø„Éº„ÅåÊ¨†Êêç„Åó„Å¶„ÅÑ„Çã„ÉÅ„É£„É≥„ÇØ„ÇíÊ§úÂá∫"""
        async with self.postgres_pool.acquire() as conn:
            results = await conn.fetch("""
                SELECT id, document_id, embedding_status
                FROM document_chunks 
                WHERE embedding_status = 'completed'
                AND (dense_vector_id IS NULL 
                     OR sparse_vector_id IS NULL 
                     OR multi_vector_id IS NULL)
            """)
            return [dict(r) for r in results]
```

---

## ‚ö° „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊúÄÈÅ©Âåñ

### 1. „Éë„Éº„ÉÜ„Ç£„Ç∑„Éß„Éã„É≥„Ç∞Êà¶Áï•

```sql
-- Êó•‰ªò„Éô„Éº„Çπ„Éë„Éº„ÉÜ„Ç£„Ç∑„Éß„Éã„É≥„Ç∞ÔºàÂ§ßÈáè„Éá„Éº„ÇøÂØæÂøúÔºâ
CREATE TABLE documents_partitioned (
    LIKE documents INCLUDING ALL
) PARTITION BY RANGE (created_at);

-- ÊúàÂà•„Éë„Éº„ÉÜ„Ç£„Ç∑„Éß„É≥‰ΩúÊàê
CREATE TABLE documents_2024_01 PARTITION OF documents_partitioned
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE documents_2024_02 PARTITION OF documents_partitioned
    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- Ëá™Âãï„Éë„Éº„ÉÜ„Ç£„Ç∑„Éß„É≥‰ΩúÊàêÈñ¢Êï∞
CREATE OR REPLACE FUNCTION create_monthly_partition(target_date DATE)
RETURNS void AS $$
DECLARE
    start_date DATE;
    end_date DATE;
    partition_name TEXT;
BEGIN
    start_date := date_trunc('month', target_date);
    end_date := start_date + INTERVAL '1 month';
    partition_name := 'documents_' || to_char(start_date, 'YYYY_MM');
    
    EXECUTE format(
        'CREATE TABLE IF NOT EXISTS %I PARTITION OF documents_partitioned
         FOR VALUES FROM (%L) TO (%L)',
        partition_name, start_date, end_date
    );
END;
$$ LANGUAGE plpgsql;
```

### 2. „Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÊúÄÈÅ©Âåñ

```sql
-- Ë§áÂêà„Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÔºà„Çà„Åè‰ΩøÁî®„Åï„Çå„ÇãÊ§úÁ¥¢Êù°‰ª∂Ôºâ
CREATE INDEX idx_chunks_search_optimized 
    ON document_chunks (embedding_status, document_id, position)
    WHERE embedding_status = 'completed';

-- ÈÉ®ÂàÜ„Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÔºà„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„Å™„ÇΩ„Éº„Çπ„ÅÆ„ÅøÔºâ
CREATE INDEX idx_sources_active_sync 
    ON sources (next_sync_at, source_type)
    WHERE is_active = true;

-- ‰∏¶Ë°å„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ‰ΩúÊàêÔºàÊú¨Áï™Áí∞Â¢ÉÂØæÂøúÔºâ
CREATE INDEX CONCURRENTLY idx_documents_fulltext_gin 
    ON documents USING GIN (to_tsvector('japanese', title || ' ' || content));
```

### 3. Milvus „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπË®≠ÂÆö

```python
# „Ç≥„É¨„ÇØ„Ç∑„Éß„É≥‰ΩúÊàêÊôÇ„ÅÆÊúÄÈÅ©ÂåñË®≠ÂÆö
collection_config = {
    "shards_num": 2,          # „Ç∑„É£„Éº„ÉâÊï∞
    "consistency_level": "Strong",  # Êï¥ÂêàÊÄß„É¨„Éô„É´
}

# „Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÊßãÁØâ„Éë„É©„É°„Éº„Çø
index_build_config = {
    "index_type": "HNSW",
    "metric_type": "IP",
    "params": {
        "M": 16,                    # „É°„É¢„É™ÂäπÁéá„Å®„ÅÆ„Éê„É©„É≥„Çπ
        "efConstruction": 256,       # ÊßãÁØâÊôÇÈñì„Å®Á≤æÂ∫¶„ÅÆ„Éê„É©„É≥„Çπ
        "max_memory_usage": "2GB"    # „É°„É¢„É™Âà∂Èôê
    }
}

# Ê§úÁ¥¢ÊôÇ„Éë„É©„É°„Éº„Çø
search_config = {
    "params": {
        "ef": 128,              # Ê§úÁ¥¢Á≤æÂ∫¶
        "nprobe": 16            # ‰∏¶Ë°åÊ§úÁ¥¢Êï∞
    },
    "limit": 100,              # ÂèñÂæó‰ª∂Êï∞‰∏äÈôê
    "timeout": 30              # „Çø„Ç§„É†„Ç¢„Ç¶„ÉàÔºàÁßíÔºâ
}
```

---

## ‚ùó „Çà„Åè„ÅÇ„ÇãËêΩ„Å®„ÅóÁ©¥„Å®ÂØæÁ≠ñ

### 1. „Éô„ÇØ„Çø„ÉºÊ¨°ÂÖÉ‰∏ç‰∏ÄËá¥

```python
# ‚ùå ÂïèÈ°å: Áï∞„Å™„Çã„É¢„Éá„É´„Åß„ÅÆÊ¨°ÂÖÉÊï∞Ê∑∑Âú®
def save_vector_unsafe(vector: list[float]):
    # Ê¨°ÂÖÉ„ÉÅ„Çß„ÉÉ„ÇØ„Å™„Åó„Åß‰øùÂ≠ò ‚Üí Ê§úÁ¥¢ÊôÇ„Ç®„É©„Éº
    collection.insert([{"id": "test", "vector": vector}])

# ‚úÖ ÂØæÁ≠ñ: ‰∫ãÂâçÊ¨°ÂÖÉ„ÉÅ„Çß„ÉÉ„ÇØ
def save_vector_safe(vector: list[float]):
    EXPECTED_DIM = 1024
    if len(vector) != EXPECTED_DIM:
        raise ValueError(
            f"Vector dimension mismatch: expected {EXPECTED_DIM}, "
            f"got {len(vector)}"
        )
    
    # Ê≠£Ë¶èÂåñ„ÇÇÂÆüÊñΩ
    normalized_vector = normalize_vector(vector)
    collection.insert([{"id": "test", "vector": normalized_vector}])
```

### 2. „Éà„É©„É≥„Ç∂„ÇØ„Ç∑„Éß„É≥Â¢ÉÁïå„ÅÆÂïèÈ°å

```python
# ‚ùå ÂïèÈ°å: ÂàÜÊï£„Éá„Éº„Çø„ÅÆ‰∏çÊï¥Âêà
async def save_document_unsafe(doc_data, vectors):
    # PostgreSQL‰øùÂ≠ò
    doc_id = await postgres_repo.save(doc_data)
    
    # Milvus‰øùÂ≠òÔºàÂ§±ÊïóÊôÇ„ÄÅPostgreSQL„Éá„Éº„Çø„ÅåÊÆã„ÇãÔºâ
    await milvus_client.insert(vectors)

# ‚úÖ ÂØæÁ≠ñ: Saga„Éë„Çø„Éº„É≥„Å´„Çà„ÇãÂàÜÊï£„Éà„É©„É≥„Ç∂„ÇØ„Ç∑„Éß„É≥
async def save_document_safe(doc_data, vectors):
    compensation_actions = []
    
    try:
        # 1. PostgreSQL‰øùÂ≠ò
        doc_id = await postgres_repo.save(doc_data)
        compensation_actions.append(
            lambda: postgres_repo.delete(doc_id)
        )
        
        # 2. Milvus‰øùÂ≠ò
        vector_ids = await milvus_client.insert(vectors)
        compensation_actions.append(
            lambda: milvus_client.delete(vector_ids)
        )
        
        # 3. „Éû„ÉÉ„Éî„É≥„Ç∞ÊÉÖÂ†±Êõ¥Êñ∞
        await postgres_repo.update_vector_ids(doc_id, vector_ids)
        
        return doc_id
        
    except Exception as e:
        # ÈÄÜÈ†Ü„ÅßË£úÂÑüÂá¶ÁêÜÂÆüË°å
        for action in reversed(compensation_actions):
            try:
                await action()
            except Exception as cleanup_error:
                logger.error(f"Cleanup failed: {cleanup_error}")
        raise e
```

### 3. „É°„É¢„É™„É™„Éº„ÇØ„Å®„Ç≥„Éç„ÇØ„Ç∑„Éß„É≥ÁÆ°ÁêÜ

```python
# ‚úÖ ÈÅ©Âàá„Å™„É™„ÇΩ„Éº„ÇπÁÆ°ÁêÜ
class DatabaseManager:
    def __init__(self):
        self._postgres_pool = None
        self._milvus_client = None
        self._redis_client = None
    
    async def __aenter__(self):
        # „Ç≥„Éç„ÇØ„Ç∑„Éß„É≥„Éó„Éº„É´ÂàùÊúüÂåñ
        self._postgres_pool = await asyncpg.create_pool(
            dsn=DATABASE_URL,
            min_size=5,
            max_size=20,
            command_timeout=60
        )
        
        self._milvus_client = MilvusClient(
            host=MILVUS_HOST,
            port=MILVUS_PORT,
            pool_size=10
        )
        
        self._redis_client = await aioredis.from_url(
            REDIS_URL,
            max_connections=20
        )
        
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        # ÈÅ©Âàá„Å™„É™„ÇΩ„Éº„ÇπËß£Êîæ
        if self._postgres_pool:
            await self._postgres_pool.close()
        
        if self._milvus_client:
            await self._milvus_client.close()
        
        if self._redis_client:
            await self._redis_client.close()
```

---

## üéØ ÁêÜËß£Á¢∫Ë™ç„ÅÆ„Åü„ÇÅ„ÅÆË®≠Âïè

### „Çπ„Ç≠„Éº„ÉûË®≠Ë®àÁêÜËß£
1. `documents`„ÉÜ„Éº„Éñ„É´„Åß`processing_status`„Å®`indexing_status`„ÇíÂàÜ„Åë„Å¶„ÅÑ„ÇãÁêÜÁî±„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ
2. `document_chunks`„ÉÜ„Éº„Éñ„É´„ÅÆ`parent_chunk_id`„Éï„Ç£„Éº„É´„Éâ„ÅÆÁî®ÈÄî„Å®ÈöéÂ±§ÊßãÈÄ†„ÅÆË°®ÁèæÊñπÊ≥ï„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ
3. Milvus„ÅßDense„ÄÅSparse„ÄÅMulti-Vector„ÇíÂà•„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥„Å´ÂàÜ„Åë„Çã„É°„É™„ÉÉ„Éà„Çí3„Å§Êåô„Åí„Å¶„Åè„Å†„Åï„ÅÑ

### „Éá„Éº„ÇøÊï¥ÂêàÊÄßÁêÜËß£
1. PostgreSQL-MilvusÈñì„ÅÆ„Éá„Éº„ÇøÊï¥ÂêàÊÄß„Çí‰øù„Å§„Åü„ÇÅ„Å´ÂÆüË£Ö„Åï„Çå„Åü‰ªïÁµÑ„Åø„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ
2. ÂàÜÊï£„Éà„É©„É≥„Ç∂„ÇØ„Ç∑„Éß„É≥„ÅßSaga„Éë„Çø„Éº„É≥„Çí‰ΩøÁî®„Åô„ÇãÁêÜÁî±„Å®Ë£úÂÑüÂá¶ÁêÜ„ÅÆÈáçË¶ÅÊÄß„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ
3. `cleanup_document_vectors()`„Éà„É™„Ç¨„ÉºÈñ¢Êï∞„ÅåÂøÖË¶Å„Å™ÁêÜÁî±„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ

### „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÁêÜËß£
1. Â§ßÈáè„Éá„Éº„ÇøÂá¶ÁêÜ„Åß„Éë„Éº„ÉÜ„Ç£„Ç∑„Éß„Éã„É≥„Ç∞„ÅåÊúâÂäπ„Å™ÁêÜÁî±„Å®„ÄÅÈÅ©Âàá„Å™ÂàÜÂâ≤Êà¶Áï•„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ
2. Milvus„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„Éë„É©„É°„Éº„ÇøÔºàM„ÄÅefConstructionÔºâ„ÅÆË™øÊï¥ÊåáÈáù„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ
3. ÈÉ®ÂàÜ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„Çí‰ΩøÁî®„Åô„Çã„Åì„Å®„ÅÆÂà©ÁÇπ„Å®ÈÅ©Áî®Â†¥Èù¢„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ

### ÈÅãÁî®ÁêÜËß£
1. „Éá„Éº„ÇøÊï¥ÂêàÊÄß„ÉÅ„Çß„ÉÉ„Ç´„Éº„ÅßÊ§úÂá∫„Åô„Åπ„Åç4Á®ÆÈ°û„ÅÆ‰∏çÊï¥Âêà„Å®„Åù„ÅÆÂΩ±Èüø„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ
2. „Éô„ÇØ„Çø„ÉºÊ¨°ÂÖÉ‰∏ç‰∏ÄËá¥„ÅåÁô∫Áîü„Åô„ÇãÂéüÂõ†„Å®‰∫ãÂâçÈò≤Ê≠¢Á≠ñ„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ
3. „Ç≥„Éç„ÇØ„Ç∑„Éß„É≥„Éó„Éº„É´Ë®≠ÂÆö„ÅßËÄÉÊÖÆ„Åô„Åπ„Åç„Éë„É©„É°„Éº„Çø„Çí5„Å§Êåô„Åí„Å¶„Åè„Å†„Åï„ÅÑ

---

## üìö Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó

„Éá„Éº„Çø„É¢„Éá„É´Ë®≠Ë®à„ÇíÁêÜËß£„Åß„Åç„Åü„Çâ„ÄÅÊ¨°„ÅÆÂ≠¶ÁøíÊÆµÈöé„Å´ÈÄ≤„Çì„Åß„Åè„Å†„Åï„ÅÑÔºö

- **Step06**: Ë™çË®º„ÉªË™çÂèØ„Ç∑„Çπ„ÉÜ„É† - JWT„ÉªAPI KeyË™çË®º„ÅÆÂÆüË£ÖË©≥Á¥∞
- **Step07**: „Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞„Å®Áõ£Ë¶ñ - ‰æãÂ§ñÂá¶ÁêÜ„Éª„É≠„Ç∞„Éª„É°„Éà„É™„ÇØ„ÇπÂèéÈõÜ
- **Step08**: „Éá„Éó„É≠„Ç§„É°„É≥„Éà„Å®ÈÅãÁî® - Docker„ÉªKubernetes„ÉªCI/CD

ÈÅ©Âàá„Å™„Éá„Éº„Çø„É¢„Éá„É´Ë®≠Ë®à„ÅØ„ÄÅ„Ç∑„Çπ„ÉÜ„É†„ÅÆÊã°ÂºµÊÄß„Å®‰øùÂÆàÊÄß„ÇíÊ±∫ÂÆö„Åô„ÇãÈáçË¶Å„Å™Ë¶ÅÁ¥†„Åß„Åô„ÄÇÊ¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó„Åß„ÅØ„ÄÅ„Åì„ÅÆ„Éá„Éº„Çø„ÇíÂÆâÂÖ®„Å´‰øùË≠∑„Åô„ÇãË™çË®º„ÉªË™çÂèØ„Ç∑„Çπ„ÉÜ„É†„Å´„Å§„ÅÑ„Å¶Â≠¶Áøí„Åó„Åæ„Åô„ÄÇ